{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fK6M_2yX5WQA",
        "outputId": "37833dd9-bbbf-464b-a0f5-50b1d954c7a1"
      },
      "outputs": [],
      "source": [
        "!pip install torch==2.0.1 torchvision==0.15.2 pytorchvideo==0.1.5 ffmpeg-python opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WC1CQk75eFN4",
        "outputId": "9f9a35a1-b66d-489a-929d-ee82528edcfd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from pytorchvideo.models.hub import slowfast_r50  # SlowFast model\n",
        "\n",
        "# Load pre-trained SlowFast model\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = slowfast_r50(pretrained=True).to(device)\n",
        "model.eval()  # Set to evaluation mode\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "OEVxMmFfeFeB",
        "outputId": "1c92e296-a972-4688-ed3e-c9380b97f998"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()  # Upload a video from your computer\n",
        "\n",
        "# Get the uploaded filename\n",
        "video_path = list(uploaded.keys())[0]\n",
        "print(f\"Uploaded video: {video_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWG-HmGceQex",
        "outputId": "b72eb37a-7495-477a-dbfd-bec35c259d45"
      },
      "outputs": [],
      "source": [
        "import ffmpeg\n",
        "import numpy as np\n",
        "import torch\n",
        "from pytorchvideo.transforms import (\n",
        "    ApplyTransformToKey, UniformTemporalSubsample, ShortSideScale\n",
        ")\n",
        "from torchvision.transforms import Compose\n",
        "from torchvision.transforms._transforms_video import NormalizeVideo\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def load_and_preprocess_video(video_path):\n",
        "    # Probe the video file to get properties\n",
        "    probe = ffmpeg.probe(video_path)\n",
        "    video_stream = next((stream for stream in probe['streams'] if stream['codec_type'] == 'video'), None)\n",
        "\n",
        "    if video_stream is None:\n",
        "        raise ValueError(\"No video stream found in file!\")\n",
        "\n",
        "    width, height = int(video_stream['width']), int(video_stream['height'])\n",
        "\n",
        "    # Resize while keeping aspect ratio\n",
        "    new_short_side = 256\n",
        "    if height < width:\n",
        "        new_height, new_width = new_short_side, int((new_short_side / height) * width)\n",
        "    else:\n",
        "        new_width, new_height = new_short_side, int((new_short_side / width) * height)\n",
        "\n",
        "    # Decode video using FFmpeg\n",
        "    out, _ = (\n",
        "        ffmpeg.input(video_path)\n",
        "        .filter('scale', new_width, new_height)\n",
        "        .filter('fps', fps=10)  # Reduce FPS for efficiency\n",
        "        .output('pipe:', format='rawvideo', pix_fmt='rgb24')\n",
        "        .run(capture_stdout=True, quiet=True)\n",
        "    )\n",
        "\n",
        "    # Compute number of frames\n",
        "    num_frames = len(out) // (new_height * new_width * 3)\n",
        "\n",
        "    if num_frames == 0:\n",
        "        raise ValueError(\"FFmpeg failed to extract frames. Check the video format!\")\n",
        "\n",
        "    # Reshape array correctly\n",
        "    video_frames = np.frombuffer(out, np.uint8).reshape([num_frames, new_height, new_width, 3])\n",
        "\n",
        "    # Convert to PyTorch tensor and permute to [C, T, H, W]\n",
        "    video_tensor = torch.tensor(video_frames, dtype=torch.uint8).permute(0, 3, 1, 2).float() / 255.0  # [T, C, H, W]\n",
        "\n",
        "    # Ensure correct number of frames (pad if needed)\n",
        "    target_frames = 32  # Expected frame count\n",
        "    if num_frames < target_frames:\n",
        "        pad_frames = target_frames - num_frames\n",
        "        padding = torch.zeros((pad_frames, 3, new_height, new_width))  # Padding with black frames\n",
        "        video_tensor = torch.cat([video_tensor, padding], dim=0)  # Add padding frames\n",
        "\n",
        "    # Permute to [C, T, H, W] before normalization\n",
        "    video_tensor = video_tensor.permute(1, 0, 2, 3)  # Convert [T, C, H, W] -> [C, T, H, W]\n",
        "\n",
        "    # Apply PyTorchVideo transforms\n",
        "    transform = ApplyTransformToKey(\n",
        "        key=\"video\",\n",
        "        transform=Compose([\n",
        "            UniformTemporalSubsample(target_frames),  # Sample exactly 32 frames\n",
        "            ShortSideScale(size=256),\n",
        "            NormalizeVideo(mean=[0.45, 0.45, 0.45], std=[0.225, 0.225, 0.225]),  # Applied on [C, T, H, W]\n",
        "        ])\n",
        "    )\n",
        "\n",
        "    video_tensor = transform({\"video\": video_tensor})[\"video\"]\n",
        "\n",
        "    return video_tensor.unsqueeze(0).to(device)  # Add batch dimension: [1, C, T, H, W]\n",
        "\n",
        "# Load and preprocess video\n",
        "video_tensor = load_and_preprocess_video(video_path)\n",
        "print(\"Video Tensor Shape:\", video_tensor.shape)  # Expected: [1, 3, 32, H, W]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38r8wZuSeSsP",
        "outputId": "87f21ee2-7444-4a09-86d1-6db668146238"
      },
      "outputs": [],
      "source": [
        "def pack_pathway(video_tensor):\n",
        "    \"\"\"\n",
        "    Convert the input video tensor into a list of tensors for SlowFast model.\n",
        "    Slow Pathway -> Sample every 4th frame\n",
        "    Fast Pathway -> Original frame rate\n",
        "    \"\"\"\n",
        "    fast_pathway = video_tensor  # Keep full frame rate\n",
        "    slow_pathway = torch.index_select(video_tensor, 2, torch.linspace(0, video_tensor.shape[2] - 1, video_tensor.shape[2] // 4).long().to(video_tensor.device))\n",
        "\n",
        "    return [slow_pathway, fast_pathway]  # Return as a list\n",
        "\n",
        "# Prepare the video for SlowFast model\n",
        "video_tensor = load_and_preprocess_video(video_path)  # [1, 3, 32, H, W]\n",
        "input_tensor = pack_pathway(video_tensor)  # List of two tensors\n",
        "\n",
        "# Pass through model\n",
        "with torch.no_grad():\n",
        "    outputs = model(input_tensor)\n",
        "\n",
        "# Get top-5 predictions\n",
        "top5_probs, top5_classes = torch.topk(torch.softmax(outputs, dim=1), 5)\n",
        "print(\"Top 5 Predicted Action Classes:\", top5_classes.tolist())\n",
        "print(\"Top 5 Probabilities:\", top5_probs.tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8zlRqzfeUuu",
        "outputId": "d6d5a38e-e0b8-4616-8819-3f7d093678ae"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "\n",
        "# Download Kinetics-400 class labels\n",
        "KINETICS_LABELS_URL = \"https://raw.githubusercontent.com/deepmind/kinetics-i3d/master/data/label_map.txt\"\n",
        "with urllib.request.urlopen(KINETICS_LABELS_URL) as f:\n",
        "    kinetics_labels = [line.decode('utf-8').strip() for line in f.readlines()]\n",
        "\n",
        "# Print top 5 predicted actions\n",
        "print(\"Top 5 Predicted Actions:\")\n",
        "for i in range(5):\n",
        "    action_name = kinetics_labels[top5_classes[0, i].item()]\n",
        "    print(f\"{i+1}. {action_name} - Probability: {top5_probs[0, i].item():.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w87rMRDOfPJ4"
      },
      "source": [
        "Display Video with Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDVkBl1GfDNG",
        "outputId": "29c440ea-83e9-4232-a1a4-569cf0b60ccf"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "# Load the video using OpenCV\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Get video properties\n",
        "frame_width = int(cap.get(3))\n",
        "frame_height = int(cap.get(4))\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "# Create a VideoWriter to save the processed video\n",
        "output_path = \"output_video.mp4\"\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec\n",
        "out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "# Get the top predicted action\n",
        "predicted_action = kinetics_labels[top5_classes[0, 0].item()]\n",
        "probability = top5_probs[0, 0].item()\n",
        "\n",
        "# Read and process video frame by frame\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Convert BGR (OpenCV default) to RGB\n",
        "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Overlay text: Predicted Action\n",
        "    label = f\"{predicted_action} ({probability:.2f})\"\n",
        "    cv2.putText(frame, label, (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
        "\n",
        "    # Convert RGB back to BGR (for OpenCV writing)\n",
        "    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    # Write frame to the output video\n",
        "    out.write(frame)\n",
        "\n",
        "# Release everything\n",
        "cap.release()\n",
        "out.release()\n",
        "\n",
        "print(\"Processed video saved as:\", output_path)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
